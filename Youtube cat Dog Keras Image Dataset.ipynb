{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAT and DOG prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load dataset using my smart Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Loaded Successfully ..........\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import cv2\n",
    "    import os\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    print(\"Library Loaded Successfully ..........\")\n",
    "except:\n",
    "    print(\"Library not Found ! \")\n",
    "\n",
    "\n",
    "class MasterImage(object):\n",
    "\n",
    "    def __init__(self,PATH='', IMAGE_SIZE = 50):\n",
    "        self.PATH = PATH\n",
    "        self.IMAGE_SIZE = IMAGE_SIZE\n",
    "\n",
    "        self.image_data = []\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        self.CATEGORIES = []\n",
    "\n",
    "        # This will get List of categories\n",
    "        self.list_categories = []\n",
    "\n",
    "    def get_categories(self):\n",
    "        for path in os.listdir(self.PATH):\n",
    "            if '.DS_Store' in path:\n",
    "                pass\n",
    "            else:\n",
    "                self.list_categories.append(path)\n",
    "        print(\"Found Categories \",self.list_categories,'\\n')\n",
    "        return self.list_categories\n",
    "\n",
    "    def Process_Image(self):\n",
    "        try:\n",
    "            \"\"\"\n",
    "            Return Numpy array of image\n",
    "            :return: X_Data, Y_Data\n",
    "            \"\"\"\n",
    "            self.CATEGORIES = self.get_categories()\n",
    "            for categories in self.CATEGORIES:                                                  # Iterate over categories\n",
    "\n",
    "                train_folder_path = os.path.join(self.PATH, categories)                         # Folder Path\n",
    "                class_index = self.CATEGORIES.index(categories)                                 # this will get index for classification\n",
    "\n",
    "                for img in os.listdir(train_folder_path):                                       # This will iterate in the Folder\n",
    "                    new_path = os.path.join(train_folder_path, img)                             # image Path\n",
    "\n",
    "                    try:        # if any image is corrupted\n",
    "                        image_data_temp = cv2.imread(new_path,cv2.IMREAD_GRAYSCALE)                 # Read Image as numbers\n",
    "                        image_temp_resize = cv2.resize(image_data_temp,(self.IMAGE_SIZE,self.IMAGE_SIZE))\n",
    "                        self.image_data.append([image_temp_resize,class_index])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            data = np.asanyarray(self.image_data)\n",
    "\n",
    "            # Iterate over the Data\n",
    "            for x in data:\n",
    "                self.x_data.append(x[0])        # Get the X_Data\n",
    "                self.y_data.append(x[1])        # get the label\n",
    "\n",
    "            X_Data = np.asarray(self.x_data) / (255.0)      # Normalize Data\n",
    "            Y_Data = np.asarray(self.y_data)\n",
    "\n",
    "            # reshape x_Data\n",
    "\n",
    "            X_Data = X_Data.reshape(-1, self.IMAGE_SIZE, self.IMAGE_SIZE, 1)\n",
    "\n",
    "            return X_Data, Y_Data\n",
    "        except:\n",
    "            print(\"Failed to run Function Process Image \")\n",
    "\n",
    "    def pickle_image(self):\n",
    "\n",
    "        \"\"\"\n",
    "        :return: None Creates a Pickle Object of DataSet\n",
    "        \"\"\"\n",
    "        # Call the Function and Get the Data\n",
    "        X_Data,Y_Data = self.Process_Image()\n",
    "\n",
    "        # Write the Entire Data into a Pickle File\n",
    "        pickle_out = open('X_Data','wb')\n",
    "        pickle.dump(X_Data, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # Write the Y Label Data\n",
    "        pickle_out = open('Y_Data', 'wb')\n",
    "        pickle.dump(Y_Data, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        print(\"Pickled Image Successfully \")\n",
    "        return X_Data,Y_Data\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        try:\n",
    "            # Read the Data from Pickle Object\n",
    "            X_Temp = open('X_Data','rb')\n",
    "            X_Data = pickle.load(X_Temp)\n",
    "\n",
    "            Y_Temp = open('Y_Data','rb')\n",
    "            Y_Data = pickle.load(Y_Temp)\n",
    "\n",
    "            print('Reading Dataset from PIckle Object')\n",
    "\n",
    "            return X_Data,Y_Data\n",
    "\n",
    "        except:\n",
    "            print('Could not Found Pickle File ')\n",
    "            print('Loading File and Dataset  ..........')\n",
    "\n",
    "            X_Data,Y_Data = self.pickle_image()\n",
    "            return X_Data,Y_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not Found Pickle File \n",
      "Loading File and Dataset  ..........\n",
      "Found Categories  ['dogs', 'cats'] \n",
      "\n",
      "Pickled Image Successfully \n",
      "(8000, 80, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/soumilshah/IdeaProjects/mytensorflow/Dataset/training_set'\n",
    "a = MasterImage(PATH=path,\n",
    "                    IMAGE_SIZE=80)\n",
    "\n",
    "X_Data,Y_Data = a.load_dataset()\n",
    "print(X_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten,Conv2D,MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(150, (3, 3), input_shape=X_Data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(75, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_Data, Y_Data, batch_size=40, epochs=3, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
